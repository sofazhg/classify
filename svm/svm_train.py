#! /usr/bin/python3
# encoding: utf-8

"""
@author: Shaohua Zhang
@contact: sofazhg@outlook.com
@file: svm_train.py
@time: 2019-03-17 15:20
"""

import sklearn
import os
import sys
import time
from feature_gen import list_1mer
from feature_gen import dict_2mer
from feature_gen import feature_gen

start = time.process_time()


def SVC_train(data_feature, data_label):  #train SVM with the best paramaters generated by svm_search.py
    from sklearn.model_selection import train_test_split
    from sklearn.externals import joblib
    from sklearn.svm import SVC
    X_train, X_test, y_train, y_test = train_test_split(data_feature, data_label, test_size=0.25)
    clf = SVC(C=10.0, cache_size=200, class_weight='balanced', coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False)
    clf = clf.fit(X_train, y_train)  #fitting model
    print(clf.score(X_test, y_test))  #print accuracy performed on the test set
    joblib.dump(clf, r'./model/clf.pkl')  #save trained SVM classifile as clf.pkl


l_1mer = list_1mer()
l_2mer = dict_2mer(l_1mer)
word_train = open(r'./temp/word_train.txt', mode='r', encoding='utf-8')
pinyin_train = open(r'./temp/pinyin_train.txt', mode='r', encoding='utf-8')
Data_Feature = []
Data_Label = []

content1 = word_train.readlines()
for i in range(len(content1)):  #input all 35536 word samples for training SVM classifier
    Data_Feature.append(feature_gen(l_2mer, content1[i]))
    Data_Label.append(1)  #data_label of word is 1

content2 = pinyin_train.readlines()
for j in range(len(content2)):  #input all 35536 pinyin samples for training SVM classifier
    Data_Feature.append(feature_gen(l_2mer, content2[j]))
    Data_Label.append(0)  #data_label of word is 0

SVC_train(Data_Feature, Data_Label)  #training SVM classifier

print('Program running time:')
end = time.process_time()
print(str(end - start))
